# -*- coding: utf-8 -*-
"""Yolov5_tail_light_state.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FdU7O4FEw9VjqjuVqTrPVQnpOuMyV-eY

Tail light state detection
"""

!nvidia-smi

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
#Change directory to my drive
# %cd /content/drive/MyDrive

# clone YOLOv5 repository inside my drive
!git clone https://github.com/ultralytics/yolov5  # clone



# Commented out IPython magic to ensure Python compatibility.
#Change the directory to yolov5 folder
# %cd /content/drive/MyDrive/yolov5

pwd

# clone YOLOv5 repository
#!git clone https://github.com/ultralytics/yolov5  # clone repo
#!git clone https://github.com/ultralytics/yolov5
#%cd yolov5
#!git reset --hard 886f1c03d839575afecb059accf74296fad395b6

#!git clone https://github.com/ultralytics/yolov5  # clone
#%cd yolov5
!pip install -r requirements.txt



# install dependencies as necessary
#!pip install -qr requirements.txt  # install dependencies 
import torch
import os

from IPython.display import Image, clear_output  # to display images
#from utils.google_utils import gdrive_download  # to download models/datasets

# clear_output()
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))





!sudo apt-get install tree



#follow the link below to get your download code from from Roboflow
!pip install -q roboflow
from roboflow import Roboflow
rf = Roboflow(model_format="yolov5", notebook="roboflow-yolov5")

#set up environment
#os.environ["DATASET_DIRECTORY"] = "/content/datasets"

!pwd

# Commented out IPython magic to ensure Python compatibility.
#%cd /content/yolov5

#from roboflow import Roboflow
#rf = Roboflow(api_key="VBga3rv5Fm5vK8RrHYml")
#project = rf.workspace().project("Tail_light_brake_state_003")
#dataset = project.version(2).download("yolov5")


#from roboflow import Roboflow
#rf = Roboflow(api_key="VBga3rv5Fm5vK8RrHYml")
#project = rf.workspace("new-workspace-ujmr8").project("tail_light_and_brake_state")
#dataset = project.version(3).download("yolov5")

# %cd /content/drive/MyDrive/yolov5
from roboflow import Roboflow
rf = Roboflow(api_key="VBga3rv5Fm5vK8RrHYml")
project = rf.workspace("new-workspace-ujmr8").project("tail_light_and_brake_state")
dataset = project.version(4).download("yolov5")

#TLBS No Augmentation dataset
#from roboflow import Roboflow
#rf = Roboflow(api_key="VBga3rv5Fm5vK8RrHYml")
#project = rf.workspace("new-workspace-ujmr8").project("tail_light_and_brake_state")
#dataset = project.version(5).download("yolov5")



!tree

# Commented out IPython magic to ensure Python compatibility.
# this is the YAML file  wrote so that we're loading into this notebook with our data
# %cat {dataset.location}/data.yaml

# define number of classes based on YAML
import yaml
with open(dataset.location + "/data.yaml", 'r') as stream:
    num_classes = str(yaml.safe_load(stream)['nc'])

# Commented out IPython magic to ensure Python compatibility.
#this is the model configuration we will use for our tutorial 
#%cat /content/drive/MyDrive/yolov5/models/yolov5s.yaml

#%cat /content/yolov5/models/yolov5s.yaml

# %cat /content/drive/MyDrive/yolov5/models/yolov5l.yaml



#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))

# Commented out IPython magic to ensure Python compatibility.
# %%writetemplate /content/drive/MyDrive/yolov5/models/custom_yolov5s.yaml
# #%%writetemplate /content/yolov5/models/custom_yolov5s.yaml
# 
# # parameters
# nc: {num_classes}  # number of classes
# depth_multiple: 0.33  # model depth multiple
# width_multiple: 0.50  # layer channel multiple
# 
# # anchors
# anchors:
#   - [10,13, 16,30, 33,23]  # P3/8
#   - [30,61, 62,45, 59,119]  # P4/16
#   - [116,90, 156,198, 373,326]  # P5/32
# 
# # YOLOv5 backbone
# backbone:
#   # [from, number, module, args]
#   [[-1, 1, Focus, [64, 3]],  # 0-P1/2
#    [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
#    [-1, 3, BottleneckCSP, [128]],
#    [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
#    [-1, 9, BottleneckCSP, [256]],
#    [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
#    [-1, 9, BottleneckCSP, [512]],
#    [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
#    [-1, 1, SPP, [1024, [5, 9, 13]]],
#    [-1, 3, BottleneckCSP, [1024, False]],  # 9
#   ]
# 
# # YOLOv5 head
# head:
#   [[-1, 1, Conv, [512, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 6], 1, Concat, [1]],  # cat backbone P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 13
# 
#    [-1, 1, Conv, [256, 1, 1]],
#    [-1, 1, nn.Upsample, [None, 2, 'nearest']],
#    [[-1, 4], 1, Concat, [1]],  # cat backbone P3
#    [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)
# 
#    [-1, 1, Conv, [256, 3, 2]],
#    [[-1, 14], 1, Concat, [1]],  # cat head P4
#    [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)
# 
#    [-1, 1, Conv, [512, 3, 2]],
#    [[-1, 10], 1, Concat, [1]],  # cat head P5
#    [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)
# 
#    [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
#   ]

!pip install clearml

!clearml-init

pip install wandb



# Commented out IPython magic to ensure Python compatibility.
# # train yolov5s on custom data for 100 epochs
# # time its performance
# %%time
# %cd /content/drive/MyDrive/yolov5
# #%cd /content/yolov5
# !python train.py --img 416 --batch 32 --epochs 100 --data ./Tail_light_and_brake_state-4/data.yaml --cfg ./models/yolov5l.yaml --weights '' --name yolov5l_results  --cache
# #!python train.py --resume
#

#clearInterval(colab)



# Commented out IPython magic to ensure Python compatibility.
# Start tensorboard

# %load_ext tensorboard
# %tensorboard --logdir runs

# we can also output some older school graphs if the tensor board isn't working for whatever reason... 
from utils.plots import plot_results  # plot results.txt as results.png
Image(filename='/content/yolov5/runs/train/yolov5l_results/results.png', width=1000)  # view results.png

# first, display our ground truth data
print("GROUND TRUTH TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg', width=900)

# print out an augmented training example
print("GROUND TRUTH AUGMENTED TRAINING DATA:")
Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)

# Commented out IPython magic to ensure Python compatibility.
# trained weights are saved by default in our weights folder
# %ls runs/

# Commented out IPython magic to ensure Python compatibility.
# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!
# use the best weights!
# %cd /content/drive/MyDrive/yolov5
#%cd /content/yolov5/
!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ./Tail_light_and_brake_state-5/test/images

# Commented out IPython magic to ensure Python compatibility.
# video detection (upload video)
# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!
# use the best weights!
# %cd /content/yolov5/
!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ./Tail_light_and_brake_state-2/test/Driving_Tour_Trim.mp4

#display inference on ALL test images
#this looks much better with longer training above

import glob
from IPython.display import Image, display

for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG 
    display(Image(filename=imageName))
    print("\n")

from google.colab import drive
drive.mount('/content/gdrive')

!cp -r /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My\ Drive



# Commented out IPython magic to ensure Python compatibility.
# %ls runs/train/yolov5s_results/weights